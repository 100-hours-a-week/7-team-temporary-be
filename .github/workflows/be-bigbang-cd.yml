name: BigBang-BE-CD
on:
  push:
    branches:
      - 'release/**'
      - 'main'
permissions:
  contents: read
  id-token: write

jobs:
  build:
    name: Build Artifact (BE)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up JDK 25
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 25

      - name: Grant execute permission for gradlew
        run: chmod +x gradlew

      - name: Cache Gradle
        uses: actions/cache@v4
        with:
          path: |
            ~/.gradle/caches
            ~/.gradle/wrapper
          key: gradle-${{ runner.os }}-${{ hashFiles('**/*.gradle*', '**/gradle-wrapper.properties') }}
          restore-keys: |
            gradle-${{ runner.os }}-

      - name: Build (Spring Boot)
        shell: bash
        run: |
          set -euo pipefail          
          ./gradlew clean bootJar -x test -x spotlessJava --no-daemon
          
      - name: Package artifact
        shell: bash
        run: |
          set -euo pipefail
          JAR_PATH=$(ls -1 build/libs/*.jar 2>/dev/null | head -n 1)
          if [ -z "${JAR_PATH}" ]; then
            echo "Build output jar not found under build/libs"; exit 1;
          fi
          mkdir -p release_bundle
          cp "${JAR_PATH}" release_bundle/app.jar
          tar -czf app.tar.gz -C release_bundle .

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: be-app-build
          path: app.tar.gz
          retention-days: 3

  deploy-staging:
    name: Deploy to BE Staging (develop -> release)
    runs-on: ubuntu-latest
    needs: build

    # PR merge 완료 된것들 (base가 release, head가 develop)
    if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/heads/release/') }}
    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: be-app-build
          path: .

      - name: Upload artifact to server
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.HOST_STAGING }}
          username: ${{ secrets.USER_STAGING }}
          key: ${{ secrets.SSH_KEY_STAGING }}
          port: 22
          source: app.tar.gz
          target: /tmp

      - name: Deploy via SSH (staging)
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.HOST_STAGING }}
          username: ${{ secrets.USER_STAGING }}
          key: ${{ secrets.SSH_KEY_STAGING }}
          port: 22
          script_stop: true
          script: |
            set -euo pipefail

            APP_DIR="${{ secrets.APP_DIR }}"
            PM2_NAME="${{ secrets.PM2_NAME }}"

            RELEASE_ROOT="${APP_DIR}/releases"
            CURRENT_LINK="${APP_DIR}/current"
            NEXT_RELEASE="${RELEASE_ROOT}/$(date +%Y%m%d%H%M%S)"

            mkdir -p "${RELEASE_ROOT}" "${NEXT_RELEASE}"

            # 아티팩트 압축 해제 (app.jar 포함)
            if [ ! -f /tmp/app.tar.gz ]; then
              echo "ERROR: /tmp/app.tar.gz not found"; exit 1;
            fi
            tar -xzf /tmp/app.tar.gz -C "${NEXT_RELEASE}"

            JAR_PATH="${NEXT_RELEASE}/app.jar"
            if [ ! -f "${JAR_PATH}" ]; then
              echo "ERROR: app.jar not found in release"; exit 1;
            fi

            # current 심볼릭 링크 업데이트
            ln -sfn "${NEXT_RELEASE}" "${CURRENT_LINK}"

            echo "== [STAGING] pm2 restart"
            cd /home/ubuntu/be
            pm2 reload ecosystem.config.js --update-env || pm2 start ecosystem.config.js

            # 오래된 릴리즈 정리 (최근 3개만 유지)
            ls -dt "${RELEASE_ROOT}"/* 2>/dev/null | tail -n +4 | xargs -r rm -rf || true

      - name: Post-deploy k6 SLO check (staging)
        shell: bash
        env:
          # Assumes HOST_STAGING is a public IP or resolvable hostname.
          # If your staging uses HTTPS and a domain, change this to https://<domain>/api
          BASE_URL: https://stg.molip.today/api
        run: |
          set -euo pipefail
          echo "== Install k6 on runner =="
          sudo apt-get update
          sudo apt-get install -y gnupg ca-certificates curl
          curl -fsSL https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6

          TEST_DATE="$(date +%F)"
          echo "BASE_URL=${BASE_URL}"
          echo "TEST_DATE=${TEST_DATE}"
          
          echo "== Wait for backend to be ready (avoid 502 right after deploy) =="
          # We expect one of: 200/400/401/403 when backend is reachable.
          # We want to avoid 502/503/504 which usually indicates Nginx upstream not ready.
          READY_URL="${BASE_URL}/day-plan/schedule?date=${TEST_DATE}&page=1&size=1"
          for i in {1..30}; do
            CODE=$(curl -sS -o /dev/null -w "%{http_code}" "${READY_URL}" || echo "000")
            if [ "${CODE}" = "200" ] || [ "${CODE}" = "400" ] || [ "${CODE}" = "401" ] || [ "${CODE}" = "403" ]; then
              echo "Backend ready (http ${CODE})";
              break
            fi
            echo "Not ready yet (http ${CODE}), retry..."
            sleep 2
          done
          CODE=$(curl -sS -o /dev/null -w "%{http_code}" "${READY_URL}" || echo "000")
          if [ "${CODE}" = "502" ] || [ "${CODE}" = "503" ] || [ "${CODE}" = "504" ] || [ "${CODE}" = "000" ]; then
            echo "FAIL: backend still not ready (http ${CODE}). Abort k6.";
            exit 1;
          fi


          # Light-load SLO gate script (post-deploy verification)
          cat > k6-slo-gate.js <<'K6'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate, Trend } from 'k6/metrics';

          // 1) Custom metrics (SLI)
          const errorRate = new Rate('errors');
          const signupSuccess = new Rate('signup_success');
          const loginSuccess = new Rate('login_success');
          const scheduleCreateSuccess = new Rate('schedule_create_success');
          const scheduleQuerySuccess = new Rate('schedule_query_success');
          const scheduleUpdateSuccess = new Rate('schedule_update_success');
          const scheduleCompleteSuccess = new Rate('schedule_complete_success');

          const scheduleQueryLatency = new Trend('schedule_query_latency');
          const scheduleCreateLatency = new Trend('schedule_create_latency');
          const scheduleUpdateLatency = new Trend('schedule_update_latency');
          const scheduleCompleteLatency = new Trend('schedule_complete_latency');

          // SLO PASS conditions (provided)
          // - Availability >= 99.9% => errors rate <= 0.001
          // - Query p95 < 300ms
          // - Complete success >= 99.95% => rate >= 0.9995
          // - Write p95 < 300ms (create/update)
          export const options = {
            stages: [
              { duration: '20s', target: 2 },
              { duration: '2m', target: 3 },
              { duration: '20s', target: 0 },
            ],
            thresholds: {
              errors: ['rate<=0.001'],
              schedule_query_latency: ['p(95)<300'],
              schedule_complete_success: ['rate>=0.9995'],
              schedule_create_latency: ['p(95)<300'],
              schedule_update_latency: ['p(95)<300'],
              signup_success: ['rate>0.99'],
              login_success: ['rate>0.99'],
            },
          };

          const BASE_URL = __ENV.BASE_URL;
          const DATE = __ENV.TEST_DATE;

          export function setup() {
            const email = `k6_user_${Date.now()}@test.com`;

            const signupRes = http.post(
              `${BASE_URL}/users`,
              JSON.stringify({
                email,
                password: 'password@12A',
                nickname: 'nickname',
                gender: 'MALE',
                birth: '1990.01.01',
                focusTimeZone: 'MORNING',
                dayEndTime: '22:40',
              }),
              { headers: { 'Content-Type': 'application/json' }, tags: { name: 'signup' } }
            );

            const signupOk = check(signupRes, { 'signup 2xx': (r) => r.status === 200 || r.status === 201 });
            signupSuccess.add(signupOk);
            errorRate.add(!signupOk);
            if (!signupOk) throw new Error(`Signup failed: ${signupRes.status}`);

            const loginRes = http.post(
              `${BASE_URL}/token`,
              JSON.stringify({ email, password: 'password@12A' }),
              { headers: { 'Content-Type': 'application/json' }, tags: { name: 'login' } }
            );

            const loginOk = check(loginRes, { 'login 200': (r) => r.status === 200 });
            loginSuccess.add(loginOk);
            errorRate.add(!loginOk);
            if (!loginOk) throw new Error(`Login failed: ${loginRes.status}`);

            const accessToken = loginRes.json('data.accessToken');
            if (!accessToken) throw new Error('No accessToken in login response');

            const authHeaders = {
              headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${accessToken}`,
              },
            };

            const firstGetRes = http.get(
              `${BASE_URL}/day-plan/schedule?date=${DATE}&page=1&size=10`,
              { ...authHeaders, tags: { name: 'schedule_query' } }
            );

            const firstQueryOk = check(firstGetRes, { 'initial query 200': (r) => r.status === 200 });
            scheduleQuerySuccess.add(firstQueryOk);
            scheduleQueryLatency.add(firstGetRes.timings.duration);
            errorRate.add(!firstQueryOk);
            if (!firstQueryOk) throw new Error(`Initial query failed: ${firstGetRes.status}`);

            const dayPlanId = firstGetRes.json('data.dayPlanId');
            if (!dayPlanId) throw new Error('No dayPlanId found');

            return { accessToken, dayPlanId };
          }

          export default function (data) {
            const { accessToken, dayPlanId } = data;

            const auth = {
              headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${accessToken}`,
              },
            };

            // (A) Query 2x
            for (let i = 0; i < 2; i++) {
              const res = http.get(
                `${BASE_URL}/day-plan/schedule?date=${DATE}&page=1&size=10`,
                { ...auth, tags: { name: 'schedule_query' } }
              );

              const ok = check(res, { 'schedule query 200': (r) => r.status === 200 });
              scheduleQuerySuccess.add(ok);
              scheduleQueryLatency.add(res.timings.duration);
              errorRate.add(!ok);
              sleep(0.2);
            }

            // (B) Writes occasionally
            if (__ITER % 3 === 0) {
              // Create: avoid time-overlap collisions by using a larger time window + retries.
              // We do NOT count business-rule overlap (409 / overlap-message) as availability errors.
              const slotLenMin = 5;           // shorter slots reduce overlap probability
              const windowStartMin = 0 * 60;  // 00:00
              const windowEndMin = 23 * 60 + 55; // 23:55
              const windowSpan = (windowEndMin - windowStartMin) - slotLenMin;

              function fmt(min) {
                const h = String(Math.floor(min / 60)).padStart(2, '0');
                const m = String(min % 60).padStart(2, '0');
                return `${h}:${m}`;
              }

              function isOverlapBusinessError(res) {
                const s = res?.status || 0;
                if (s === 409) return true;
                if (s === 400) {
                  const b = (res.body || '').toLowerCase();
                  // common patterns: "overlap", "conflict", Korean "겹"
                  if (b.includes('overlap') || b.includes('conflict') || b.includes('겹')) return true;
                }
                return false;
              }

              const title = `k6 일정 ${__VU}-${__ITER}-${Date.now()}`;
              let created = false;
              let lastRes = null;

              for (let attempt = 0; attempt < 10; attempt++) {
                // Spread times by VU/ITER and add a time-based component so repeated runs don't collide.
                const epochMin = Math.floor(Date.now() / 60000);
                const offset = (epochMin + (__VU * 97) + (__ITER * 13) + (attempt * 7)) % windowSpan;
                const startMin = windowStartMin + offset;
                const endMin = startMin + slotLenMin;

                const startAt = fmt(startMin);
                const endAt = fmt(endMin);

                lastRes = http.post(
                  `${BASE_URL}/day-plan/${dayPlanId}/schedule`,
                  JSON.stringify({
                    title,
                    type: 'FIXED',
                    startAt,
                    endAt,
                    estimatedTimeRange: 'HOUR_1_TO_2',
                    focusLevel: 5,
                    isUrgent: false,
                  }),
                  { ...auth, tags: { name: 'schedule_create' } }
                );

                // Success
                if (lastRes.status === 200 || lastRes.status === 201) {
                  created = true;
                  break;
                }

                // Overlap/business conflict: retry with different slot; do NOT count as availability error
                if (isOverlapBusinessError(lastRes)) {
                  console.warn(`create overlap/conflict (attempt ${attempt + 1}/10) status=${lastRes.status}`);
                  sleep(0.1);
                  continue;
                }

                // Other errors: treat as availability error and stop retrying
                break;
              }

              const createOk = check(lastRes, {
                'schedule create 2xx': (r) => r && (r.status === 200 || r.status === 201),
              });

              scheduleCreateSuccess.add(createOk);
              if (createOk) {
                scheduleCreateLatency.add(lastRes.timings.duration);
              }

              // Only count non-business failures as availability errors
              if (!createOk && lastRes && !isOverlapBusinessError(lastRes)) {
                console.error(`create failed status=${lastRes.status} body=${(lastRes.body || '').slice(0, 200)}`);
                errorRate.add(true);
              }

              // If we never managed to create due to overlaps, log and continue without failing availability
              if (!createOk && lastRes && isOverlapBusinessError(lastRes)) {
                console.warn('create skipped due to repeated overlaps; not counted as availability error');
              }

              const listRes = http.get(
                `${BASE_URL}/day-plan/schedule?date=${DATE}&page=1&size=10`,
                { ...auth, tags: { name: 'schedule_query' } }
              );

              const listOk = check(listRes, { 'schedule list 200': (r) => r.status === 200 });
              scheduleQuerySuccess.add(listOk);
              scheduleQueryLatency.add(listRes.timings.duration);
              errorRate.add(!listOk);

              const schedule = listOk ? listRes.json('data.content.0') : null;
              const scheduleId = schedule?.scheduleId;

              if (scheduleId && __ITER % 6 === 0) {
                const updatePayload = {
                  title: `k6 변경 ${Date.now()}`,
                  type: schedule.type,
                  startAt: schedule.startAt,
                  endAt: schedule.endAt,
                  estimatedTimeRange: schedule.estimatedTimeRange,
                  focusLevel: schedule.focusLevel,
                  isUrgent: schedule.isUrgent,
                };

                const updateRes = http.put(
                  `${BASE_URL}/schedule/${scheduleId}`,
                  JSON.stringify(updatePayload),
                  { ...auth, tags: { name: 'schedule_update' } }
                );

                const updateOk = check(updateRes, {
                  'schedule update 2xx': (r) => r.status === 200 || r.status === 204,
                });
                scheduleUpdateSuccess.add(updateOk);
                scheduleUpdateLatency.add(updateRes.timings.duration);
                errorRate.add(!updateOk);

                const completeRes = http.patch(
                  `${BASE_URL}/schedule/${scheduleId}/status`,
                  JSON.stringify({ status: 'TODO' }),
                  { ...auth, tags: { name: 'schedule_complete' } }
                );

                const completeOk = check(completeRes, {
                  'schedule complete 204': (r) => r.status === 204,
                });
                scheduleCompleteSuccess.add(completeOk);
                scheduleCompleteLatency.add(completeRes.timings.duration);
                errorRate.add(!completeOk);
              }
            }

            sleep(0.6);
          }
          K6

          # Run. If k6 thresholds fail, this step (and job) fails.
          BASE_URL="${BASE_URL}" TEST_DATE="${TEST_DATE}" k6 run k6-slo-gate.js




  deploy_gcp:
    name: Deploy to GCP (main)
    needs: build
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/heads/main') }}
    env:
      GCP_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
      GCP_ZONE: ${{ secrets.GCP_ZONE }}
      GCP_INSTANCE: ${{ secrets.GCE_INSTANCE_NAME }}
      GCP_USER: ${{ secrets.GCE_USER }}
      GCP_TARGET_DIR: ${{ secrets.APP_DIR_AWS }}
      GCP_SERVICE: ${{ secrets.PM2_NAME }}

    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: be-app-build
          path: .

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT_EMAIL }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}


      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: Force set active project (critical)
        shell: bash
        run: |
          set -euo pipefail
          gcloud config set project "${GCP_PROJECT}"
          echo "ACTIVE_PROJECT=$(gcloud config get-value project)"
          gcloud config list
          
          #      - name: SSH into VM (public IP) and run simple commands
          #        shell: bash
          #        run: |
          #          set -euo pipefail
          #          gcloud compute ssh "${GCP_INSTANCE}" \
          #            --project "${GCP_PROJECT}" \
          #            --zone "${GCP_ZONE}" \
          #            --quiet \
          #            --command "echo 'SSH_OK'; whoami; hostname; uname -a"
      

      # 1) tar 업로드  2) 원격에서 preflight + blue/green + switch
      # 파일이동만 처리
      - name: Upload artifact (GCP scp)
        run: |
          set -euo pipefail
          gcloud compute scp app.tar.gz \
            ${GCP_USER}@${GCP_INSTANCE}:/tmp/be-app.tar.gz \
            --zone="${GCP_ZONE}" \
            --project="${GCP_PROJECT}" \
            --quiet

      # ssh 접속
      - name: Deploy (remote script)
        run: |
          set -euo pipefail
           gcloud compute ssh "${GCP_USER}@${GCP_INSTANCE}" \
            --zone "${GCP_ZONE}" \
            --project "${GCP_PROJECT}" \
            --quiet \
            --command "bash -se" <<'EOSSH'
          
          set -euo pipefail
          
          APP_DIR="${{ secrets.APP_DIR }}"        # home/ubuntu/be
          RELEASE_DIR="${APP_DIR}/releases"
          CURRENT_DIR="${APP_DIR}/current"
          
          BLUE_PORT="${{ secrets.BLUE_PORT }}"      # 8080
          GREEN_PORT="${{ secrets.GREEN_PORT }}"    # 8081
          PM2_BLUE="${{ secrets.PM2_BLUE_NAME }}"   # molip-be-blue
          PM2_GREEN="${{ secrets.PM2_GREEN_NAME }}" # molip-be-green
          
          HEALTH_BLUE="${{ secrets.HEALTH_BLUE_URL }}"   # healthurl:8080
          HEALTH_GREEN="${{ secrets.HEALTH_GREEN_URL }}" # health:8081
          
          UPSTREAM_CONF="${{ secrets.NGINX_UPSTREAM_CONF }}" #  /etc/nginx/sites-available/molip
          
          # PREFLIGHT 상수 (필요하면 조정)
          MIN_MEM=1843200
          MAX_LA=1.0
          DISK_MIN_REM=3
          
          # (선택) DB preflight를 쓰려면 mysql client가 서버에 있어야 함
          DB_HOST="${{ secrets.DB_HOST }}"  # localhost
          DB_PORT="${{ secrets.DB_PORT }}"  # 3306
          DB_USER="${{ secrets.DB_USER }}"  # molip
          DB_PASS="${{ secrets.DB_PASS }}"  # molip1234
          DB_MAX_CONN="${{ secrets.DB_MAX_CONNECTIONS }}"  # 151             
          GREEN_POOL="${{ secrets.GREEN_DB_POOL }}" # 10
          
          echo "== [1] Preflight: MemAvailable =="
          MEM_AVAIL=$(grep '^MemAvailable:' /proc/meminfo | awk '{print $2}')
          [ "${MEM_AVAIL}" -ge "${MIN_MEM}" ] || { echo "FAIL: MEM 부족 (${MEM_AVAIL} < ${MIN_MEM})"; exit 1; }
          
          # echo "== [2] Preflight: LoadAvg =="
          # LA1=$(awk '{print $1}' /proc/loadavg)
          # LA5=$(awk '{print $2}' /proc/loadavg)
          # awk -v la1="$LA1" -v la5="$LA5" -v max="$MAX_LA" 'BEGIN { exit ! (la1 <= max && la5 <= max) }' \
          #  || { echo "FAIL: LA1=${LA1}, LA5=${LA5} > ${MAX_LA}"; exit 1; }
          
          # echo "== [3] Preflight: Disk Free =="
          # FREE_GB=$(df -BG / | awk 'NR==2 {gsub(/G/,"",$4); print $4}')
          # [ "${FREE_GB}" -ge "${DISK_MIN_REM}" ] || { echo "FAIL: 디스크 부족 (${FREE_GB}G < ${DISK_MIN_REM}G)"; exit 1; }
          
          echo "== Extract artifact =="
          # (필수) 파일 존재 확인: 없으면 여기서 바로 종료
          ls -al /tmp || true
          [ -f /tmp/be-app.tar.gz ] || { echo "FAIL: /tmp/be-app.tar.gz not found"; exit 1; }
          
          sudo mkdir -p "${RELEASE_DIR}"
          TS="$(date +%Y%m%d%H%M%S)"
          NEW_REL="${RELEASE_DIR}/${TS}"
          sudo mkdir -p "${NEW_REL}"
          
          # (중요) NEW_REL이 root 소유일 수 있으니 tar도 sudo
          sudo tar -xzf /tmp/be-app.tar.gz -C "${NEW_REL}"

          [ -f "${NEW_REL}/app.jar" ] || { echo "FAIL: app.jar not found"; exit 1; }
        
          # (중요) current 링크도 권한 이슈 방지
          sudo ln -sfn "${NEW_REL}" "${CURRENT_DIR}"
          
          echo "== Detect ACTIVE port from Nginx upstream =="
          ACTIVE_PORT=$(grep -Eo '127.0.0.1:(8080|8081)+' "${UPSTREAM_CONF}" | head -n 1 | cut -d: -f2)
          
          if [ "${ACTIVE_PORT}" = "${BLUE_PORT}" ]; then
           ACTIVE_PM2="${PM2_BLUE}"
           IDLE_PM2="${PM2_GREEN}"
           IDLE_PORT="${GREEN_PORT}"
           IDLE_HEALTH="${HEALTH_GREEN}"
          else
           ACTIVE_PM2="${PM2_GREEN}"
           IDLE_PM2="${PM2_BLUE}"
           IDLE_PORT="${BLUE_PORT}"
           IDLE_HEALTH="${HEALTH_BLUE}"
          fi
          
          echo "ACTIVE_PM2=${ACTIVE_PM2} (port=${ACTIVE_PORT})"
          echo "IDLE_PM2=${IDLE_PM2} (port=${IDLE_PORT})"
          
           # 배포
          echo "== Start IDLE process =="
          # 디버깅: pm2 실행 직전 위치/사용자 확인
          echo "[DEBUG] before pm2: whoami=$(whoami)"
          echo "[DEBUG] before pm2: pwd=$(pwd)"
          echo "[DEBUG] APP_DIR=${APP_DIR}"
          echo "[DEBUG] list pwd"
          ls -al "$(pwd)" || true
          echo "[DEBUG] list APP_DIR"
          ls -al "${APP_DIR}" || true

          pm2 delete "${IDLE_PM2}" >/dev/null 2>&1 || true
          pm2 start "${APP_DIR}/ecosystem.config.js" --only "${IDLE_PM2}" --env production          
          echo "== Health check IDLE (max 60s) =="
          for i in {1..30}; do
          if curl -fsS "${IDLE_HEALTH}" >/dev/null; then
          echo "Health OK"
          break
          fi
          sleep 2
          done
          curl -fsS "${IDLE_HEALTH}" >/dev/null || {
          echo "FAIL: Health check";
          exit 1;
          }
          
          echo "== Switch Nginx upstream -> ${IDLE_PORT} =="
          sudo sed -i -E "0,/127\\.0\\.0\\.1:[8080|8081]+/s//127.0.0.1:${IDLE_PORT}/" "${UPSTREAM_CONF}"
          sudo nginx -t
          sudo systemctl reload nginx || sudo nginx -s reload
          
          echo "== Verify after switch =="
          if ! curl -fsS "${IDLE_HEALTH}" >/dev/null; then
          echo "FAIL: Post-switch health -> rollback upstream"
          sudo sed -i -E "0,/127\\.0\\.0\\.1:(8080|8081)/s//127.0.0.1:${ACTIVE_PORT}/" "${UPSTREAM_CONF}"          
          sudo nginx -t
          sudo systemctl reload nginx || sudo nginx -s reload-
          exit 1
          fi
          
          echo "== Stop OLD process: ${ACTIVE_PM2} =="
          pm2 delete "${ACTIVE_PM2}" >/dev/null 2>&1 || true
          pm2 save >/dev/null 2>&1 || true
          
          echo "== DEPLOY SUCCESS =="
          EOSSH
